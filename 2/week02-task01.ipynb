{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment: Выбор числа соседей\n",
    "\n",
    "In this task, you need to select the optimal value of k for the KNN algorithm. We will use the Wine data set, where we need to predict the grape variety from which the wine is made using the results of chemical analyzes.\n",
    "\n",
    "В этом задании вам нужно подобрать оптимальное значение k для алгоритма kNN. Будем использовать набор данных Wine, где требуется предсказать сорт винограда, из которого изготовлено вино, используя результаты химических анализов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from lib.helpersmd import write_to_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Download the Wine sample at https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data (the file is also attached to this task)\n",
    "\n",
    "2- Extract the attributes and classes from the data. The class is written in the first column (three variants), the features are in the columns from the second to the last. \n",
    "\n",
    "More information about the essence of the features can be found at https://archive.ics.uci.edu/ml/datasets/Wine (see also the wine.names file attached to the task)\n",
    "\n",
    "    1- Загрузите выборку Wine по адресу https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data (файл также приложен к этому заданию)\n",
    "\n",
    "    2- Извлеките из данных признаки и классы. Класс записан в первом столбце (три варианта), признаки — в столбцах со второго по последний. Более подробно о сути признаков можно прочитать по адресу https://archive.ics.uci.edu/ml/datasets/Wine (см. также файл wine.names, приложенный к заданию)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 load dataset , split X,Y\n",
    "data=pandas.read_csv('wine.data',header=None)\n",
    "#2\n",
    "data=data.as_matrix(columns=None)\n",
    "y=data[:,0]\n",
    "X=data[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Quality assessment should be carried out by cross-validation in 5 blocks (5-fold). Create a splitter generator that mixes the selection before forming the blocks (shuffle = True). To reproduce the result, create a KFold generator with a fixed parameter random_state = 42. As a measure of quality, use the proportion of correct answers (accuracy).\n",
    "\n",
    "4- Find the classification accuracy for cross-validation for the nearest neighbor method (sklearn.neighbors.KNeighborsClassifier), for k from 1 to 50. At which k did the optimal quality get? What is it equal to (a number in the range from 0 to 1)? These results will be answers to questions 1 and 2.\n",
    "\n",
    "    3- Оценку качества необходимо провести методом кросс-валидации по 5 блокам (5-fold). Создайте генератор разбиений, который перемешивает выборку перед формированием блоков (shuffle=True). Для воспроизводимости результата, создавайте генератор KFold с фиксированным параметром random_state=42. В качестве меры качества используйте долю верных ответов (accuracy).\n",
    "\n",
    "    4- Найдите точность классификации на кросс-валидации для метода k ближайших соседей (sklearn.neighbors.KNeighborsClassifier), при k от 1 до 50. При каком k получилось оптимальное качество? Чему оно равно (число в интервале от 0 до 1)? Данные результаты и будут ответами на вопросы 1 и 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  3.  Cross validation iterators\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#shuffle=True for randomly mixing objects of the sample\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=42)\n",
    "#for train, test in kf.split(X):\n",
    "#     print(\"%s %s\" % (train, test))\n",
    "\n",
    "#4\n",
    "val_max=0\n",
    "k_max=0\n",
    "\n",
    "for k in range(1,51): #(1,51):\n",
    "    clf = KNeighborsClassifier(n_neighbors=k)\n",
    "    score=sum(cross_val_score(clf,X,y,cv=cv))/5\n",
    "    if score>val_max:\n",
    "        val_max=score\n",
    "        k_max=k\n",
    "    \"\"\"\n",
    "    #this my implementation for cross_val_score\n",
    "    S=0\n",
    "    for train, test in cv.split(X):\n",
    "        # print(\"%s %s\" % (train, test))\n",
    "        Xtrain=X[train]\n",
    "        ytrain=y[train]\n",
    "        Xtest=X[test]\n",
    "        ytest=y[test]\n",
    "        \n",
    "        neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "        neigh.fit(Xtrain, ytrain)\n",
    "        \n",
    "        val=sum(neigh.predict(Xtest)==ytest)/float(len(ytest))\n",
    "        S+=val\n",
    "    S/=5\n",
    "    print sm1,S\n",
    "    if S>val_max:\n",
    "        val_max=S\n",
    "        k_max=k\n",
    "    \"\"\"\n",
    "write_to_file(k_max,\"week%d-A%dT%d.out\"%(2,1,1))\n",
    "write_to_file(val_max,\"week%d-A%dT%d.out\"%(2,1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5- Scale the characteristics using the function sklearn.preprocessing.scale. Find the optimal k for cross-validation again.\n",
    "\n",
    "6- What is the optimal value of k after bringing the characteristics to the same scale? Answer the questions 3 and 4. Did the scaling of the signs help?\n",
    "\n",
    "    5- Произведите масштабирование признаков с помощью функции sklearn.preprocessing.scale. Снова найдите оптимальное k на кросс-валидации.\n",
    "\n",
    "    6- Какое значение k получилось оптимальным после приведения признаков к одному масштабу? Приведите ответы на вопросы 3 и 4. Помогло ли масштабирование признаков?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 \n",
    "from sklearn.preprocessing import scale\n",
    "X_norm=scale(X,with_mean=True,with_std=True)\n",
    "\n",
    "#6\n",
    "val_max=0\n",
    "k_max=0\n",
    "for k in range(1,51): #(1,51):\n",
    "    clf = KNeighborsClassifier(n_neighbors=k)\n",
    "    score=sum(cross_val_score(clf,X,y,cv=cv))/5\n",
    "    if score>val_max:\n",
    "        val_max=score\n",
    "        k_max=k\n",
    "        \n",
    "write_to_file(k_max,\"week%d-A%dT%d.out\"%(2,1,3))\n",
    "write_to_file(val_max,\"week%d-A%dT%d.out\"%(2,1,4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
